{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f89c9f6-fa9f-4233-af04-e0b7cc90b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch,torchvision\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "# Preproccessing\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    RobustScaler,\n",
    "    MinMaxScaler,\n",
    "    MaxAbsScaler,\n",
    "    OneHotEncoder,\n",
    "    Normalizer,\n",
    "    Binarizer\n",
    ")\n",
    "# Decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# Model Eval\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,accuracy_score,precision_score,f1_score,recall_score\n",
    "# Models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor,VotingRegressor,BaggingRegressor,RandomForestRegressor,RandomTreesEmbedding\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from catboost import CatBoost,CatBoostRegressor\n",
    "from xgboost import XGBRegressor,XGBRFRegressor\n",
    "from flaml import AutoML\n",
    "# Other\n",
    "import pickle\n",
    "import wandb\n",
    "\n",
    "PROJECT_NAME = 'House-Prices-Advanced-Regression-Techniques-V11'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db3530c-5e74-41e7-bc33-a6bbd958f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(469)\n",
    "np.random.seed(469)\n",
    "random.seed(469)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0584d7d9-dd0e-4a17-9ad1-39f0740b4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa55e1b-75f4-44e9-984a-892481d19e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model,X,y,valid=False):\n",
    "    preds = model.predict(X)\n",
    "    if valid:\n",
    "        results = {\n",
    "            'val mean_absolute_error':mean_absolute_error(y_true=y,y_pred=preds),\n",
    "            'val mean_squared_error':mean_squared_error(y_true=y,y_pred=preds),\n",
    "        }\n",
    "    else:\n",
    "        results = {\n",
    "            'mean_absolute_error':mean_absolute_error(y_true=y,y_pred=preds),\n",
    "            'mean_squared_error':mean_squared_error(y_true=y,y_pred=preds),\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba57acfe-cf19-4c76-86a5-5364fc9074b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe(data,col):\n",
    "    max_num = data[col].quantile(0.95)\n",
    "    min_num = data[col].quantile(0.05)\n",
    "    data = data[data[col] > max_num]\n",
    "    data = data[data[col] < min_num]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ca183e-b3ac-4659-9361-ad0452329948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_to_int(data,col):\n",
    "    data_col = data[col].to_dict()\n",
    "    idx = -1\n",
    "    labels_and_int_index = {}\n",
    "    for data_col_vals in data_col.values():\n",
    "        if data_col_vals not in labels_and_int_index.keys():\n",
    "            idx += 1\n",
    "            labels_and_int_index[data_col_vals] = idx\n",
    "    new_data = []\n",
    "    for data_col_vals in data_col.values():\n",
    "        new_data.append(labels_and_int_index[data_col_vals])\n",
    "    data[col] = new_data\n",
    "    return data,idx,labels_and_int_index,new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f807cd9-b8ce-4f6f-878b-0a6121383613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(model,name):\n",
    "    data = pd.read_csv('./data/test.csv')\n",
    "    ids = data['Id']\n",
    "    for col,missing in zip(list(data.columns),data.isna().sum()):\n",
    "        if missing > 0:\n",
    "            try:\n",
    "                data[col] = data[col].fillna(data[col].median())\n",
    "            except:\n",
    "                i = data[col].value_counts().to_dict()\n",
    "                data[col] = data[col].fillna(i[list(i.keys())[0]])\n",
    "    one_hot_cols = []\n",
    "    for col,dtype in zip(list(data.columns),data.dtypes):\n",
    "        if dtype == object:\n",
    "            try:\n",
    "                data[col].astype(float)\n",
    "            except:\n",
    "                one_hot_cols.append(col)\n",
    "    data = mct.transform(data.astype(str))\n",
    "    data = data.astype(float)\n",
    "    data = data.toarray()\n",
    "    preds = model.predict(data)\n",
    "    df = pd.DataFrame({'Id':ids,'SalePrice':preds})\n",
    "    df.to_csv(f'./submissions/{name}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec49983-4fd6-44a8-9cff-19b8fe39d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,X_train,X_test,y_train,y_test,name):\n",
    "    wandb.init(project=PROJECT_NAME,name=name)\n",
    "    model.fit(X_train,y_train)\n",
    "    wandb.log(valid(model,X_train,y_train,True))\n",
    "    wandb.log(valid(model,X_train,y_train,False))\n",
    "    make_submission(model,name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68d359fe-1b1a-4213-aaa6-d8f22879435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col,missing in zip(list(data.columns),data.isna().sum()):\n",
    "    if missing > 0:\n",
    "        try:\n",
    "            data[col] = data[col].fillna(data[col].median())\n",
    "        except:\n",
    "            i = data[col].value_counts().to_dict()\n",
    "            data[col] = data[col].fillna(i[list(i.keys())[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ecfdd71-f960-4f8d-ab82-5a6f3fbfaa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b4c92d4-db21-46f5-a150-14c3b32723e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col,dtype in zip(list(data.columns),data.dtypes):\n",
    "    if dtype == object:\n",
    "        try:\n",
    "            data[col].astype(float)\n",
    "        except:\n",
    "            one_hot_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfafeca5-006c-4ddf-b37d-097dfad506fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('SalePrice',axis=1)\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ac7ddd-eb38-40f8-9faf-2c4193baf8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mct = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown='ignore'),one_hot_cols),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "X = mct.fit_transform(X.astype(str))\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c02d302-1354-4663-9773-b2658c0c855b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 305)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abc790e7-2104-47c9-ac7a-670b2d7f457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.0625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be2fe6ea-4d2d-4fdc-9699-c0e10656e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(GradientBoostingRegressor(),X_train,X_test,y_train,y_test,'baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5613905c-088a-4906-afe1-9b7ea9e03ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de35268a-ff49-4113-8619-d7b70b359c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_old = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37843b76-4d0a-49cf-89d7-7e6570f6983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA()\n",
    "# X_train =pca.fit_transform(X_train)\n",
    "# train(GradientBoostingRegressor(),X_train,X_test,y_train,y_test,'PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39a50ae3-d77b-4719-803b-f0bda0b94170",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_old.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c86126f-3446-46a2-93f5-7c073822bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = KernelPCA()\n",
    "# X_train =pca.fit_transform(X_train)\n",
    "# train(GradientBoostingRegressor(),X_train,X_test,y_train,y_test,'KernelPCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b491621-8c61-4fea-97a1-9d2448ce8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cadcd8cb-c4f6-4a58-94eb-7bf7b979240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train_old.copy()\n",
    "# pca = SelectKBest()\n",
    "# X_train =pca.fit_transform(X_train,y_train)\n",
    "# train(GradientBoostingRegressor(),X_train,X_test,y_train,y_test,'SelectKBest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea92f034-31b6-4dbc-bab2-66481b491460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train_old.copy()\n",
    "# pca = RFECV(GradientBoostingRegressor(),step=1, cv=1)\n",
    "# X_train =pca.fit_transform(X_train,y_train)\n",
    "# train(GradientBoostingRegressor(),X_train,X_test,y_train,y_test,'RFECV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e6e8b61-6f78-4218-9d1c-bb2c64799b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train_old.copy()\n",
    "# pca = SelectFromModel(GradientBoostingRegressor())\n",
    "# X_train =pca.fit_transform(X_train,y_train)\n",
    "# train(GradientBoostingRegressor(),X_train,X_test,y_train,y_test,'SelectFromModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9db9bf9-b668-4c4c-871d-2bd8c83977f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    RobustScaler,\n",
    "    MinMaxScaler,\n",
    "    MaxAbsScaler,\n",
    "    OneHotEncoder,\n",
    "    Normalizer,\n",
    "    Binarizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "694b5840-65d3-4bda-931c-40003e2971dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessings = [    StandardScaler,\n",
    "    RobustScaler,\n",
    "    MinMaxScaler,\n",
    "    MaxAbsScaler,\n",
    "    OneHotEncoder,\n",
    "    Normalizer,\n",
    "    Binarizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09993048-ea6a-4691-9228-e3dfb2e77d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for preprocessing in preprocessings:\n",
    "#     X = data.drop('SalePrice',axis=1)\n",
    "#     y = data['SalePrice']\n",
    "#     mct = make_column_transformer(\n",
    "#         (preprocessing(),one_hot_cols),\n",
    "#         remainder='passthrough'\n",
    "#     )\n",
    "#     X = mct.fit_transform(X.astype(str))\n",
    "#     X = X.toarray()\n",
    "#     X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.0625)\n",
    "#     train(GradientBoostingRegressor(),X_train,X_test,y_train,y_test,f'{preprocessing}-preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50073e5a-0459-42ba-b917-9515e5defe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "#     ['KNeighborsRegressor',KNeighborsRegressor],\n",
    "#     ['LogisticRegression',LogisticRegression],\n",
    "#     ['DecisionTreeRegressor',DecisionTreeRegressor],\n",
    "#     ['GradientBoostingRegressor',GradientBoostingRegressor],\n",
    "#     ['AdaBoostRegressor',AdaBoostRegressor],\n",
    "#     ['RandomForestRegressor',RandomForestRegressor],\n",
    "#     ['BaggingRegressor',BaggingRegressor],\n",
    "#     ['GaussianNB',GaussianNB],\n",
    "#     ['ExtraTreesRegressor',ExtraTreesRegressor],\n",
    "#     ['CatBoost',CatBoost],\n",
    "#     ['CatBoostRegressor',CatBoostRegressor],\n",
    "#     ['XGBRegressor',XGBRegressor],\n",
    "#     ['XGBRFRegressor',XGBRFRegressor],\n",
    "#     ['ExtraTreesRegressor',ExtraTreesRegressor],\n",
    "#     ['RandomTreesEmbedding',RandomTreesEmbedding]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3bdf3d4-3344-4c75-b054-a82c3622350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in models:\n",
    "#     train(model[1](),X_train,X_test,y_train,y_test,f'{model[0]}-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ef524-3747-4103-ad59-8ac5420e73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5400 candidates, totalling 10800 fits\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   5.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   5.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   5.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   5.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   5.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   5.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   5.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   5.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   5.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   5.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   5.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   5.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.0s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.01, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   2.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   5.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   5.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   5.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   5.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=   1.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=   2.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=   0.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time=   3.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time=   3.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   0.6s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=   2.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=   2.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time=   4.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.5s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time=   4.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.8s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mse, learning_rate=0.001, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  13.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  13.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  27.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  27.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  27.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  27.7s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  25.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  25.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  25.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  26.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  52.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  53.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  53.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  52.8s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   3.7s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=  14.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=  14.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  37.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  37.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  37.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  37.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time= 1.3min\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.9s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  16.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  17.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  17.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  17.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  47.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  47.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  47.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  47.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   6.0s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  20.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  20.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  56.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  57.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  54.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  57.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   7.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  11.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  22.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  22.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  23.0s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  19.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  39.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  39.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  39.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  39.8s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   3.0s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=  10.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=  10.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  26.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  26.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  26.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  26.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=  55.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=  53.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=  53.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=  54.5s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  13.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  35.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  34.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  35.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  35.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   5.3s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  16.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  16.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  16.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  16.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  40.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  43.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  39.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  40.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   6.9s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  14.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  27.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  28.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  27.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  28.0s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  26.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  26.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  26.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  26.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  51.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  53.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  53.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  52.9s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   3.9s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=  14.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=  14.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=  14.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  38.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  37.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  37.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  35.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   5.5s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  17.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  18.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  17.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  17.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  47.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  47.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  48.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  48.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   7.0s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   8.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  20.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  21.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  20.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  21.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  57.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  58.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  55.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  59.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=huber, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  20.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  20.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.4s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.0s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  19.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  39.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  39.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  39.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  39.5s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.6s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  29.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  29.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=  58.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=  58.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=  58.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=  58.7s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   3.8s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  15.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  15.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  15.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  15.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  38.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  38.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  38.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  39.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.9s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  18.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  47.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  48.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  48.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  48.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   6.1s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.1, loss=quantile, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  27.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  27.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  27.7s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.9s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  23.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  47.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  47.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  47.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  47.4s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   3.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  29.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  29.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  29.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  29.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time= 1.0min\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  13.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  13.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  34.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  33.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  34.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  33.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.9s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  14.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  14.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  14.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  38.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  38.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  38.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  38.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   5.6s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=ls, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  22.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  22.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  22.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  22.7s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   1.7s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=100, warm_start=True; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=False; total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=250, warm_start=True; total time=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  37.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=False; total time=  37.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  37.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=auto, n_estimators=500, warm_start=True; total time=  37.6s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.7s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=250, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=False; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=2, max_features=log2, n_estimators=500, warm_start=True; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=False; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=25, warm_start=True; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=False; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=50, warm_start=True; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=False; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=100, warm_start=True; total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  24.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=False; total time=  24.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  24.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=250, warm_start=True; total time=  24.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=  49.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=False; total time=  50.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=  50.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=auto, n_estimators=500, warm_start=True; total time=  50.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=False; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=sqrt, n_estimators=500, warm_start=True; total time=   3.8s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=250, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=False; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=3, max_features=log2, n_estimators=500, warm_start=True; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=False; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=25, warm_start=True; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=False; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=50, warm_start=True; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=False; total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=100, warm_start=True; total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  30.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=False; total time=  30.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  30.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=250, warm_start=True; total time=  30.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=auto, n_estimators=500, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=False; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=250, warm_start=True; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=False; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=sqrt, n_estimators=500, warm_start=True; total time=   4.9s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=50, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=100, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=False; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=250, warm_start=True; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=False; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=4, max_features=log2, n_estimators=500, warm_start=True; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=False; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=25, warm_start=True; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=False; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=50, warm_start=True; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  14.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=False; total time=  14.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  14.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=100, warm_start=True; total time=  14.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  35.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=False; total time=  35.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  36.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=250, warm_start=True; total time=  35.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=False; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=auto, n_estimators=500, warm_start=True; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=False; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=100, warm_start=True; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=False; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=250, warm_start=True; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=False; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=sqrt, n_estimators=500, warm_start=True; total time=   6.7s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=False; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=25, warm_start=True; total time=   0.2s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=50, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=False; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=100, warm_start=True; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=False; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=250, warm_start=True; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=False; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=lad, max_depth=5, max_features=log2, n_estimators=500, warm_start=True; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=25, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=False; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=50, warm_start=True; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=False; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=100, warm_start=True; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=False; total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=250, warm_start=True; total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=False; total time=  27.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=auto, n_estimators=500, warm_start=True; total time=  27.4s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=False; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=50, warm_start=True; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=False; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=100, warm_start=True; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=False; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=250, warm_start=True; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=sqrt, n_estimators=500, warm_start=True; total time=   2.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=25, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n",
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=50, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=False; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=100, warm_start=True; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=False; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=250, warm_start=True; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=False; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=1, max_features=log2, n_estimators=500, warm_start=True; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=False; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=25, warm_start=True; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=False; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=50, warm_start=True; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=mae, learning_rate=0.01, loss=huber, max_depth=2, max_features=auto, n_estimators=100, warm_start=False; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'loss':['ls','lad','huber','quantile'],\n",
    "    'learning_rate':[0.1,0.01,0.001],\n",
    "    'n_estimators':[25,50,100,250,500],\n",
    "    'criterion':['friedman_mse','mse','mae'],\n",
    "    'max_depth':[1,2,3,4,5],\n",
    "    'max_features':['auto','sqrt','log2'],\n",
    "    'warm_start':[False,True],\n",
    "}\n",
    "model = GridSearchCV(GradientBoostingRegressor(),cv=2,verbose=2,param_grid=param_grid).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16adbf-153c-4bac-ad5f-c09e31161394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a848d-c1fd-4e87-81c3-9c140420f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(\n",
    "    loss=,\n",
    "    learning_rate=,\n",
    "    n_estimators=,\n",
    "    criterion=,\n",
    "    max_depth=,\n",
    "    max_features=,\n",
    "    warm_start=,\n",
    ")\n",
    "train(model,X_train,X_test,y_train,y_test,f'GradientBoostingRegressor-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81617370-2357-4d7f-bda7-6f441d6fe888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'loss':['ls','lad','huber','quantile'],\n",
    "#     'criterion':['friedman_mse','mse','mae'],\n",
    "#     'max_features':['auto','sqrt','log2'],\n",
    "#     'warm_start':[False,True],\n",
    "# }\n",
    "# model = GridSearchCV(GradientBoostingRegressor(),cv=2,verbose=2,param_grid=param_grid).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f88b5-44d2-4af1-850b-9db4fad7fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550c51e-c485-48ea-ac24-bfb9b7f6fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GradientBoostingRegressor(\n",
    "#     criterion='mse',\n",
    "#     loss='huber',\n",
    "#     max_features='sqrt',\n",
    "#     warm_start=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1fa33c-5a68-4197-a52b-23936ab837f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(model,X_train,X_test,y_train,y_test,f'GradientBoostingRegressor')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python373jvsc74a57bd0210f9608a45c0278a93c9e0b10db32a427986ab48cfc0d20c139811eb78c4bbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
